# Multi-Camera Person Tracking

This project implements **multi-camera person tracking**: assigning a consistent **global ID** to each person across multiple cameras using YOLO detection, DeepSORT tracking, and embedding-based re-identification.

## ğŸš€ Features

* Person detection using **YOLO** (via `ultralytics` library)
* Local per-camera tracking using **DeepSORT**
* Two global ID assignment strategies:

  * **Method 1** (`method1/`) â†’ Gallery-based global ID assignment
  * **Method 2** (`method2/`) â†’ Refined cross-camera matching with thresholds
* Supports multiple input videos
* Annotated output videos with bounding boxes + global IDs
* CSV logging of tracked IDs

---

## ğŸ“‚ Repository Structure

```
â”œâ”€â”€ input_videos/        # Example input videos (Single1.mp4, Double1.mp4)
â”œâ”€â”€ method1/             # Gallery-based approach
â”‚   â”œâ”€â”€ detect.py        # Runs detection + tracking
â”‚   â”œâ”€â”€ out_global/      #output videos
â”‚   â”œâ”€â”€ out_reid/        # Re-ID embeddings/logs
â”‚   â”œâ”€â”€ re-render.py     # Replays annotated outputs
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ method2/             # Refined approach
â”‚   â”œâ”€â”€ output/          #output videos
â”‚   â”œâ”€â”€ track_id.py      # Cross-camera global ID assignment
â”‚   â””â”€â”€ requirements.txt

â””â”€â”€ README.md            # Project documentation
```

---

## âš™ï¸ Installation

1. Clone this repository:

   ```bash
   git clone https://github.com/ArulSreekanth/Multi-Camera-Person-Tracking.git
   cd Multi-Camera-Person-Tracking
   ```

2. Install dependencies:

    Move to specific folder
   ```bash
   cd method1
   (or)
   cd method2
   ```
  
   ```bash
   pip install -r requirements.txt
   ```

---
## ğŸ” Approaches
- Method 1 = Offline â†’ processes full videos, uses the gallery to match across cameras after detection & tracking are done.

- Method 2 = Online â†’ assigns global IDs in real time while processing streams, using a buffer and thresholds.
### Method 1: Offline Gallery-Based Global ID Assignment

- Runs detection and local tracking on complete videos.

- Builds a gallery of embeddings for each local track.

- After processing, embeddings are compared across cameras to assign consistent global IDs.

- âœ… Suitable for offline analysis (all data available).

- âš ï¸ Cannot be used for real-time streaming.

### Method 2: Online Buffer-Based Global ID Assignment

- Runs detection and tracking while the video/stream is being processed.

- Maintains a sliding buffer of recent embeddings across cameras.

- Assigns or refines global IDs in real time using similarity + temporal consistency.

- âœ… Suitable for real-time multi-camera tracking.

- âš ï¸ May need threshold tuning for stability.

## â–¶ï¸ Usage

### Method 1: Gallery-Based Global ID

Runs YOLO + DeepSORT tracking per camera and assigns global IDs using an embedding gallery.

```bash
cd method1
python detect.py --videoA ../input_videos/Single.mp4 --videoB ../input_videos/Double.mp4
```

Re-render results with IDs:

```bash
python re-render.py --videoA ../input_videos/Single.mp4 --videoB ../input_videos/Double.mp4 --map_csv ../out_reid/global_id_map.csv --tracksA  ../out_reid/trackletsA.pkl --tracksB ../out_reid/trackletsB.pkl 
```

Outputs:

* Annotated video in `out_global/`
* Global ID CSV logs

---

### Method 2: Refined Global ID Matching

Uses a refined approach with stricter thresholds and temporal consistency.

```bash
cd method2
python track_id.py --cam1 ../input_videos/Single.mp4 --cam2 ../input_videos/Double.mp4
```

Outputs:

* Refined annotated videos in `output/`
* CSV logs with global ID assignments

---

## âš–ï¸ Parameters

Some important parameters (edit inside the scripts):

* `PERSON_CLASS_ID` â†’ YOLO class ID for â€œpersonâ€ (default = 0)
* `MATCH_THRESH` â†’ similarity threshold for cross-camera matching
* `MIN_FRAMES_FOR_GID` â†’ minimum frames before assigning a stable global ID
* `BUFFER_SIZE` (method2) â†’ number of frames kept in buffer for matching

---

## ğŸ“Š Outputs

* **Per-camera tracks** (local IDs)
* **Global ID mapping** across cameras
* **Annotated videos** stored in `output`
* **CSV logs** for analysis

---

## ğŸ“Œ Notes

* Ensure your input videos are placed in `input_videos/`
* GPU is recommended for real-time performance
* Threshold tuning is crucial for cross-camera consistency
* Method 1 is simpler but more error-prone, Method 2 is stricter and robust

---

## ğŸ“œ License

MIT
